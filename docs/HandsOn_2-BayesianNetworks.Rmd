---
title: "Hands-on workshop: Bayesian networks"
output: 
  html_notebook:
    code_folding: show
    toc: true
    number_sections: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---


<!-- # Plan of work -->

<!-- important reference  -->
<!-- https://arxiv.org/pdf/0908.3817.pdf -->

<!-- Bayesian Networks -->

<!-- - Dataset asia -->
<!-- - Définir le BN a priori (avis d'expert, manuel) -->
<!-- Entrer la structure dans R et plot le -->
<!-- - Définir un petit BN vide -->
<!--     - Apprentissage de la structure par logiciel -->
<!--     - Differentes méthodes (algo) -->
<!-- - Comparer les BNs -->
<!--     - Calculer les vraisemblance de la structure -->
<!--     - On va fixer la structure (la meilleure) -->
<!--     - Apprentissage de paramètre -->
<!--     - Prédiction -->

<!-- ----------------------------------------------------------------------------------------------------------------------------------- -->

<!-- ----------------------------------------------------------------------------------------------------------------------------------- -->


# Install R package `bnlearn`

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = '..')
if(!require(magrittr)) {install.packages("magrittr"); library(magrittr);}
# rm(list = ls())
```

## Methode 1 : Graphic User Interfaces

- Open R
    - ![Open R](imgs/R_logo.png){ width=10% }
- Open Package Installer
    - Menu / Packages & Data / Package Installer
    - ![](imgs/PackageInstallerMenu.png){ width=70% }
- install package `bnlearn`

![](imgs/PackageInstallerInterface.png){ width=49% } ![](imgs/PackageInstallerMenuSearchBnlearn.png){ width=49% }

- Click on "Get List"
    - Choose an CRAN mirrors (you are free to choose)
- search `bnlearn`
    <!-- - ![](imgs/PackageInstallerMenuSearchBnlearn.png){ width=50% } -->
- select `bnlearn` 
    - the selected line turns to blue
    - the "install Selected" buttom turns to blue
- click on "install Selected" buttom
- close the "Package Installer" window
- load the package `bnlearn`
- copy and past following code to console prompt: after `>`, then press "enter"

```{r echo = T, message=FALSE, warning=FALSE}
if(require(bnlearn)){
  print("Congratulations, the package bnlearn is correctly installed")
}else{
  source('http://bioconductor.org/biocLite.R')
  biocLite('Rgraphviz')
  biocLite("RBGL")
  install.packages("bnlearn")
  if(require(bnlearn)){
    print("Congratulations, the package bnlearn is correctly installed")
  }else print("Contact us !!!")
}
```

## Methode 2 : console prompt `>`

- copy and past following code to console prompt: after `>`, then press "enter"


```{r eval=FALSE}
if(require(bnlearn)){
  print("Congratulations, the package bnlearn is correctly installed")
}else{
  source('http://bioconductor.org/biocLite.R')
  biocLite('Rgraphviz')
  biocLite("RBGL")
  install.packages("bnlearn")
  if(require(bnlearn)){
    print("Congratulations, the package bnlearn is correctly installed")
  }else print("Contact us !!!")
}
```

-----------------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------------

# Exercise

## Data

The hands-on workshop is based on the `asia`, a small synthetic data set from Lauritzen and Spiegelhalter (1988) about lung diseases (tuberculosis, lung cancer or bronchitis) and visits to Asia.

**Source**

Lauritzen S, Spiegelhalter D (1988). "Local Computation with Probabilities on Graphical Structures and their Application to Expert Systems (with discussion)". Journal of the Royal Statistical Society: Series B (Statistical Methodology), 50(2), 157-224.

**Load**
Load the data set from the bnlearn package
```{r}
# Check declared variables in the memory
ls()
# Import the dataset called asia
data(asia)
# Delete the column called "E"
asia$E = NULL
# Verify if the dataset "asia"" appears in the memory ?
ls()
```

**Format**
The asia data set contains the following variables:

- `D` (dyspnoea),       
    - a two-level factor with levels `yes` and `no`.
- `T` (tuberculosis),   
    - a two-level factor with levels `yes` and `no`.
- `L` (lung cancer),    
    - a two-level factor with levels `yes` and `no`.
- `B` (bronchitis),     
    - a two-level factor with levels `yes` and `no`.
- `A` (visit to Asia),  
    - a two-level factor with levels `yes` and `no`.
- `S` (smoking),        
    - a two-level factor with levels `yes` and `no`.
- `X` (chest X-ray),    
    - a two-level factor with levels `yes` and `no`.
<!-- - `E` (tuberculosis versus lung cancer/bronchitis),  -->
<!--     - a two-level factor with levels `yes` and `no`. -->

**Usage**

Investigate the characteristics of `asia` using the exploratory analysis techniques

```{r}
# show this dataset 
# NOT RUN : > asia
# You may want to run asia, what it gives?

# first five lines should be enough to get a very first idea of the dataset
head(asia, N = 5)

# how many individuals ?
dim(asia)

# summarise the database with a build-in funtion summary()
summary(asia)
```

**Note**
Lauritzen and Spiegelhalter (1988) motivate this example as follows:

“Shortness-of-breath (dyspnoea) may be due to tuberculosis, lung cancer or bronchitis, or none of them, or more than one of them. A recent visit to Asia increases the chances of tuberculosis, while smoking is known to be a risk factor for both lung cancer and bronchitis. The results of a single chest X-ray do not discriminate between lung cancer and tuberculosis, as neither does the presence or absence of dyspnoea.”

Standard learning algorithms are not able to recover the true structure of the network because of the presence of a node (E) with conditional probabilities equal to both 0 and 1. Monte Carlo tests seems to behave better than their parametric counterparts.

----

## Learning Bayesian Network structure

### Expert-driven approach
#### Example { - }

```{r example_dag, fig.align="center", out.width='50%'}
# manually define a BN structure using model2network() function
dag_example = model2network("[Earthquake][Alert|Earthquake][Anxiety|Alert:Earthquake]")
# Plot the BN structure with graphviz.plot()
graphviz.plot(dag_example, sub = "Example DAG")
```

----

#### Exercise 1 : { - }

Now, it's your turn : 

**Suppose** we use the following variable names:

- A : Visit to Asia
- B : Bronchitis
- D : Dyspnea
- L : Lung Cancer
- T : Tuberculosis
- S : Smoking History
- X : Chest X-ray

##### Questions { - }

**Define a BN structure (a DAG) representing the causal relationships among these variables based on your knowledge**

- What are the causal relationships among the variables in `asia` dataset ?
- Use a BN structure (a DAG) to represent your causal relationships.
- Encode your BN structure with `model2network()` (see example above) in `R`
<!-- - What is the class of the output of function `model2network()`? -->
- Plot your BN structure with `graphviz.plot()`.

##### Solution { - }

Following code shows one possible solution. Any other BN structure is accaptable.

```{r eval=TRUE, fig.align = 'center', fig.show='hold', out.width = '33%'}
# create and plot the network structure.
dag_mydag = model2network("[A][S][T][L|S][B|S][D|B][X|L:T]")
# Plot
graphviz.plot(dag_mydag)
```

----

#### Excercise 2 { - }

Exercises are from http://www.cs.technion.ac.il/~dang/books/Learning%20Bayesian%20Networks(Neapolitan,%20Richard).pdf

Consider the following piece of medical knowledge taken from [Lauritzen and Spiegelhalter, 1988]: 

- Tuberculosis and lung cancer can each cause shortness of breath (dyspnea) and a positive chest X-ray. 
- Bronchitis is another cause of dyspnea. 
- A recent visit to Asia can increase the probability of tuberculosis. 
- Smoking can cause both lung cancer and bronchitis. 


##### Questions { - }

**Create again a DAG representing the causal relationships among these variables based on medical knowledge taken from [Lauritzen and Spiegelhalter, 1988]**

- Encode the BN structure with `model2network()`.
- Plot your BN structure with `graphviz.plot()`.

##### Solution { - }

```{r def_dag_Laur}
# creat Lauritzen's BN structure
# dag_Laur = model2network("[A][S][T|A][L|S][B|S][D|B:E][E|T:L][X|E]")
dag_Laur = model2network("[A][S][T|A][L|S][B|S][D|B:T:L][X|T:L]")
dag_Laur
```
```{r}
graphviz.plot(dag_Laur)
```

##### Compare BN structures { - }

Compare your BN structure and the BN structure based on medical knowledge taken from [Lauritzen and Spiegelhalter, 1988]



----

### Data-driven approach

#### learning algorithm 1: Inter-IAMB { - }
`inter.iamb(asia)`

```{r}
# Make sure there is no column named "E" in "asia"" database
dag_learn_ii  = inter.iamb(asia)
dag_learn_ii
graphviz.plot(dag_learn_ii, sub = "dag_learn_ii")
```


#### Setting the direction of undirected arcs { - }

Due to the way Bayesian networks are defined the network structure must be a directed acyclic graph (DAG); otherwise their parameters cannot be estimated because the factorization of the global probability distribution of the data into the local ones (one for each variable in the model) is not completely known.

If a network structure contains one or more undirected arcs, their direction can be set with the `set.arc()` function, if the direction of the arc is known or can be guessed from the experimental setting of the data:

```{r eval = TRUE, include=TRUE}
dag_learn_ii_improved = set.arc(dag_learn_ii, from = "S", to = "B")
graphviz.plot(dag_learn_ii_improved)
```

It's your turn, set S -> L in stead of S - L  

```{r}
score(set.arc(dag_learn_ii_improved, from = "S", to = "L"),asia)
score(set.arc(dag_learn_ii_improved, from = "L", to = "S"),asia)
# They have same score that is why algo Inter-IAMB can not decide which direction is better.
# But we know S -> L
dag_learn_ii_improved = set.arc(dag_learn_ii_improved, from = "S", to = "L")
graphviz.plot(dag_learn_ii_improved)
```


#### learning algorithm 1: Hill-Climbing { - }
`hc(asia)`
```{r}
dag_learn_hc = hc(asia)
dag_learn_hc
```

```{r fig.show = 'hold', out.width = '33%'}
# graphviz.plot(dag_Laur, sub = "dag_Laur")
# graphviz.plot(dag_learn_ii, sub = "dag_learn_ii")
# graphviz.plot(dag_learn_hc, sub = "dag_learn_hc")
all.equal(dag_learn_ii_improved, dag_learn_hc)
par(mfrow = c(1, 3))
graphviz.compare(dag_Laur, dag_learn_ii_improved, dag_learn_hc)
```


### Mix approach

The first step in learning a Bayesian network is structure learning, that is, using the data to determine which arcs are present in the graph that underlies the model. Normally, we would like for that to be a purely data-driven process — for the purposes of exploring the data, in benchmarking learning algorithms, or just because we do not know much about the phenomenon we are trying to model. However, in some contexts we have prior knowledge on what the structure of the network should look like and we would like to incorporate such knowledge in the structure learning process. One way to do that is to use whitelists and blacklists. Both are implemented as follows in bnlearn.

1. Arcs in the whitelist are always included in the network.
1. Arcs in the blacklist are never included in the network.
1. Any arc whitelisted and blacklisted at the same time is assumed to be whitelisted, and is thus removed from the blacklist. In other words, the whitelist has precedence over the blacklist.

These general rules are applied in slightly differently to different classes of structure learning aglorithms, because the latter search for the optimal model in different spaces and in different ways. For instance, score-based learning algorithms operate on the space of DAGs, and therefore cannot deal with whitelisted undirected arcs.


### Comparing Bayesian network structures

We can compute the network score of a particular graph for a particular data set with the score() function (manual); if the score function is not specified, the BIC score is returned for both continuous and discrete data.


```{r}
score(dag_mydag, asia)
score(dag_Laur, asia)
# score(dag_learn_ii, asia) # score cannot use partially dat (pdag) as input.
score(dag_learn_hc, asia)
```

**Remark**
The scores of `dag_Laur` and `dag_learn_hc` are almost the same.

----

----

## Learning Bayesian Network parameters

In general, there are three ways of creating a bn.fit object representing a Bayesian network:

1. a data-driven approach, learning it from a data set using bn.fit() and a network structure (in a bn object) as illustrated here;
1. an expert-driven approach, in which both the network structure and the parameters are specified by the user;
1. a hybrid approach combining the above.

We will talk about 'the first and the third ways.

### Data-driven approach

```{r}
bn_mydag          = bn.fit(x = dag_mydag,     data = asia)
bn_dag_Laur       = bn.fit(x = dag_Laur,      data = asia)
bn_dag_learn_hc   = bn.fit(x = dag_learn_hc,  data = asia)
```


```{r}
bn_dag_Laur$L
coef(bn_dag_Laur$L)
bn.fit.barchart(bn_dag_Laur$L)
```

$\frac{\mathbb{P}(L|S = yes)}{\mathbb{P}(L|S = no)} = $ `r bn_dag_Laur$L$prob[2,2]/bn_dag_Laur$L$prob[2,1]`

Specifying all the local distributions can be problematic in a large network. In most cases it can be more convenient to create a bn.fit object from (possibly dummy) data using bn.fit(), and then to modify just the local distributions of the nodes of interest.

- For discrete Bayesian networks (or discrete nodes in conditional Gaussian networks) we can extract the conditional probability table stored in the bn.fit object with coef(), modify it, and re-save it.

```{r}
dag = dag_Laur
fitted = bn.fit(dag, asia)
cpt = coef(fitted$S)

# Imagine the distribution of Smoking in a polulation is no: 70% , and yes : 30%
cpt[1:2] = c(0.7, 0.3) # The probability distribution of node S must sum to one.
fitted$S = cpt
```


<!-- Questions : -->

<!-- - Complete the construction of a Bayesian network by determining values for the conditional probability distributions in this DAG `either` based on your own subjective judgement or from data. -->

<!-- ## Exercise 2 -->
<!-- Construct again a DAG representing the causal relationships described in Exercise 1, but this time include auxiliary parent variables representing the possible values of the parameters in the conditional distributions. Suppose we use the following variable names: -->

<!-- A : Visit to Asia -->
<!-- B : Bronchitis -->
<!-- D : Dyspnea -->
<!-- L : Lung Cancer -->
<!-- T : Tuberculosis. -->
<!-- S : Smoking History -->
<!-- X : Chest X-ray -->

<!-- - Identify the auxiliary parent variables, whose values we need to ascertain, for each of the following calculations: -->

<!-- 1. P({B}|{S,D}). -->
<!-- 2. P({L}|{S, D}). -->
<!-- 3. P({T}|{S,D}). -->


<!-- ---- -->

<!-- # Structure learning -->

<!-- The first step in learning a Bayesian network is structure learning, that is, using the data to determine which arcs are present in the graph that underlies the model. Normally, we would like for that to be a purely data-driven process — for the purposes of exploring the data, in benchmarking learning algorithms, or just because we do not know much about the phenomenon we are trying to model. However, in some contexts we have prior knowledge on what the structure of the network should look like and we would like to incorporate such knowledge in the structure learning process. One way to do that is to use whitelists and blacklists. Both are implemented as follows in bnlearn. -->

<!-- - Arcs in the whitelist are always included in the network. -->
<!-- - Arcs in the blacklist are never included in the network. -->
<!-- - Any arc whitelisted and blacklisted at the same time is assumed to be whitelisted, and is thus removed from the blacklist. In other words, the whitelist has precedence over the blacklist. -->

<!-- These general rules are applied in slightly differently to different classes of structure learning aglorithms, because the latter search for the optimal model in different spaces and in different ways. For instance, score-based learning algorithms operate on the space of DAGs, and therefore cannot deal with whitelisted undirected arcs. -->



<!-- ```{r} -->
<!-- learn.net = empty.graph(names(asia)) -->
<!-- graphviz.plot(learn.net) -->

<!-- modelstring(learn.net) = "[A][S][B|S][L|S][T|A][E|L:T][D|B:E][X|E]" -->
<!-- graphviz.plot(learn.net) -->

<!-- # We can compute the network score of a particular graph for a particular data set with the score() function (manual); if the score function is not specified, the BIC score is returned for both continuous and discrete data. -->
<!-- # Other score functions can be used by changing the type, as documented in the manual page of the function. -->
<!-- score(learn.net, asia, type = "bic") -->
<!-- score(learn.net, asia, type = "aic") -->
<!-- score(learn.net, asia, type = "bde") -->

<!-- ``` -->

<!-- **Remarks** -->

<!-- - the number of variables in the network and in the data must be the same, although the order is not important. -->
<!-- - the names of the variables must match as well. -->

<!-- # Parameter learning -->

<!-- Once the structure of a DAG has been determined, the parameters can be determined as well -->

<!-- Two most common approaches are maximum likelihood estimation and Bayesian estimation (not available for GBNs in bnlearn) -->

<!-- Parameter estimates are based only on the subset of data spanning the considered variable and its parents -->

<!-- The `bn.fit` function from bnlearn will automatically determine the type of data and fit parameters -->

<!-- ```{r} -->
<!-- dag = model2network("[A][S][T|A][L|S][B|S][D|B:E][E|T:L][X|E]") -->
<!-- graphviz.plot(dag) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- fitted = bn.fit(dag, asia) -->
<!-- fitted$T -->
<!-- ``` -->

<!-- ```{r} -->
<!-- fitted$D -->
<!-- ``` -->

<!-- Creating custom fitted Bayesian networks using both data and expert knowledge -->

<!-- - For discrete Bayesian networks (or discrete nodes in conditional Gaussian networks) we can extract the conditional probability table stored in the bn.fit object with coef(), modify it, and re-save it. -->

<!-- ## Notes on learning -->

<!--  The arguments blacklist and whitelist can be specified in structure learning -->
<!-- functions to force the absence and presence of specific edges, respectively -->


<!-- # Using BNs : inference (Prediction) -->

<!-- ## Types of queries -->

<!-- - Conditional probability -->
<!--     - Interested in the marginal posterior probability distribution of variables given -->
<!-- evidence on other variables -->
<!-- - Most likely outcome (a.k.a. maximum a posteriori) -->
<!--     - Interested in finding the configuration of the variables that have the highest -->
<!-- posterior probability (discre -->
<!-- ```{r} -->
<!-- dag = model2network("[A][C][F][B|A][D|A:C][E|B:F]") -->
<!-- fitted = bn.fit(dag, learning.test) -->

<!-- fitted %>% class() -->
<!-- fitted$C -->
<!-- cpt = coef(fitted$C) -->
<!-- cpt[1:3] = c(0.50, 0.25, 0.25) -->
<!-- fitted$C = cpt -->
<!-- fitted$C -->
<!-- ``` -->

